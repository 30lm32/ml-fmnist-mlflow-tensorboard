{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/learn_io/generator_io.py:26: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Container\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/contrib/labeled_tensor/python/ops/core.py:722: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  tc.Tuple(string_types, collections.Hashable))),\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:61: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  elif not isinstance(value, collections.Sized):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1152)              4608      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 246,666\n",
      "Trainable params: 244,106\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The next two line macros is loading the module I developed automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Importing module related to fashion mnist.\n",
    "# The module is using CNN underneath to prediction over the dataset.\n",
    "from fmnist.fmnistexperiment import FMNistBuilderParameters, FMnistExperiment\n",
    "from fmnist.utils import Metrics\n",
    "\n",
    "# import warnings\n",
    "# warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "# Label of classes\n",
    "labels_dict = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "#Metrics: Accuracy, Precision, Recall, F1\n",
    "metrics = ['accuracy', Metrics.precision_m, Metrics.recall_m, Metrics.f1_m]\n",
    "\n",
    "# Creating an object instance of FMNistBuilderParameters to define module parameters.\n",
    "parameters = FMNistBuilderParameters() \\\n",
    "        .with_file_paths('../data/fashion-mnist_train.csv',\n",
    "                        '../data/fashion-mnist_test.csv') \\\n",
    "        .with_image_size(28, 28) \\\n",
    "        .with_callback_params('val_loss', 'min', 10) \\\n",
    "        .with_train_params(batch_size=2000,\n",
    "                           epochs=100,\n",
    "                           labels_dict=labels_dict,\n",
    "                           test_size=0.2,\n",
    "                           random_state=13,\n",
    "                           metrics=metrics) \\\n",
    "        .build()\n",
    "\n",
    "\n",
    "# Passing parameters to the module\n",
    "experiment = FMnistExperiment(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 31s 642us/step - loss: 1.1493 - acc: 0.6125 - precision_m: 0.6869 - recall_m: 0.5360 - f1_m: 0.5961 - val_loss: 0.5593 - val_acc: 0.7930 - val_precision_m: 0.8442 - val_recall_m: 0.7436 - val_f1_m: 0.7907\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.6397 - acc: 0.7675 - precision_m: 0.8246 - recall_m: 0.7124 - f1_m: 0.7643 - val_loss: 0.4582 - val_acc: 0.8279 - val_precision_m: 0.8679 - val_recall_m: 0.7875 - val_f1_m: 0.8258\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 34s 711us/step - loss: 0.5464 - acc: 0.7992 - precision_m: 0.8478 - recall_m: 0.7505 - f1_m: 0.7961 - val_loss: 0.4239 - val_acc: 0.8425 - val_precision_m: 0.8702 - val_recall_m: 0.8130 - val_f1_m: 0.8406\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 30s 632us/step - loss: 0.4980 - acc: 0.8176 - precision_m: 0.8585 - recall_m: 0.7767 - f1_m: 0.8155 - val_loss: 0.3908 - val_acc: 0.8517 - val_precision_m: 0.8800 - val_recall_m: 0.8257 - val_f1_m: 0.8520\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 31s 642us/step - loss: 0.4621 - acc: 0.8307 - precision_m: 0.8664 - recall_m: 0.7932 - f1_m: 0.8282 - val_loss: 0.3788 - val_acc: 0.8572 - val_precision_m: 0.8822 - val_recall_m: 0.8342 - val_f1_m: 0.8575\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 32s 658us/step - loss: 0.4303 - acc: 0.8411 - precision_m: 0.8749 - recall_m: 0.8098 - f1_m: 0.8411 - val_loss: 0.3523 - val_acc: 0.8686 - val_precision_m: 0.8897 - val_recall_m: 0.8494 - val_f1_m: 0.8691\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 45s 935us/step - loss: 0.4145 - acc: 0.8475 - precision_m: 0.8780 - recall_m: 0.8176 - f1_m: 0.8467 - val_loss: 0.3391 - val_acc: 0.8737 - val_precision_m: 0.8963 - val_recall_m: 0.8532 - val_f1_m: 0.8742\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 37s 764us/step - loss: 0.3966 - acc: 0.8543 - precision_m: 0.8840 - recall_m: 0.8275 - f1_m: 0.8549 - val_loss: 0.3352 - val_acc: 0.8765 - val_precision_m: 0.8957 - val_recall_m: 0.8592 - val_f1_m: 0.8771\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 32s 661us/step - loss: 0.3816 - acc: 0.8587 - precision_m: 0.8865 - recall_m: 0.8316 - f1_m: 0.8582 - val_loss: 0.3223 - val_acc: 0.8793 - val_precision_m: 0.8973 - val_recall_m: 0.8626 - val_f1_m: 0.8796\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 33s 686us/step - loss: 0.3686 - acc: 0.8637 - precision_m: 0.8877 - recall_m: 0.8391 - f1_m: 0.8627 - val_loss: 0.3118 - val_acc: 0.8832 - val_precision_m: 0.9009 - val_recall_m: 0.8693 - val_f1_m: 0.8848\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 33s 687us/step - loss: 0.3549 - acc: 0.8688 - precision_m: 0.8934 - recall_m: 0.8462 - f1_m: 0.8692 - val_loss: 0.3024 - val_acc: 0.8878 - val_precision_m: 0.9050 - val_recall_m: 0.8714 - val_f1_m: 0.8879\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 33s 686us/step - loss: 0.3488 - acc: 0.8719 - precision_m: 0.8951 - recall_m: 0.8500 - f1_m: 0.8719 - val_loss: 0.3076 - val_acc: 0.8833 - val_precision_m: 0.8990 - val_recall_m: 0.8685 - val_f1_m: 0.8835\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 33s 688us/step - loss: 0.3387 - acc: 0.8750 - precision_m: 0.8981 - recall_m: 0.8537 - f1_m: 0.8754 - val_loss: 0.2967 - val_acc: 0.8887 - val_precision_m: 0.9054 - val_recall_m: 0.8768 - val_f1_m: 0.8908\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 32s 672us/step - loss: 0.3298 - acc: 0.8777 - precision_m: 0.8999 - recall_m: 0.8561 - f1_m: 0.8775 - val_loss: 0.2984 - val_acc: 0.8847 - val_precision_m: 0.9012 - val_recall_m: 0.8715 - val_f1_m: 0.8861\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 36s 752us/step - loss: 0.3250 - acc: 0.8796 - precision_m: 0.9011 - recall_m: 0.8595 - f1_m: 0.8798 - val_loss: 0.2867 - val_acc: 0.8914 - val_precision_m: 0.9056 - val_recall_m: 0.8774 - val_f1_m: 0.8913\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 36s 745us/step - loss: 0.3160 - acc: 0.8838 - precision_m: 0.9047 - recall_m: 0.8644 - f1_m: 0.8841 - val_loss: 0.2824 - val_acc: 0.8944 - val_precision_m: 0.9096 - val_recall_m: 0.8828 - val_f1_m: 0.8960\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 33s 679us/step - loss: 0.3073 - acc: 0.8862 - precision_m: 0.9068 - recall_m: 0.8684 - f1_m: 0.8872 - val_loss: 0.2857 - val_acc: 0.8904 - val_precision_m: 0.9041 - val_recall_m: 0.8788 - val_f1_m: 0.8913\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 31s 656us/step - loss: 0.3097 - acc: 0.8857 - precision_m: 0.9062 - recall_m: 0.8668 - f1_m: 0.8860 - val_loss: 0.2733 - val_acc: 0.8969 - val_precision_m: 0.9128 - val_recall_m: 0.8848 - val_f1_m: 0.8986\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 32s 668us/step - loss: 0.3002 - acc: 0.8875 - precision_m: 0.9083 - recall_m: 0.8699 - f1_m: 0.8887 - val_loss: 0.2855 - val_acc: 0.8923 - val_precision_m: 0.9056 - val_recall_m: 0.8813 - val_f1_m: 0.8933\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 30s 622us/step - loss: 0.2934 - acc: 0.8912 - precision_m: 0.9096 - recall_m: 0.8742 - f1_m: 0.8915 - val_loss: 0.2747 - val_acc: 0.8962 - val_precision_m: 0.9094 - val_recall_m: 0.8847 - val_f1_m: 0.8969\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 30s 625us/step - loss: 0.2888 - acc: 0.8935 - precision_m: 0.9113 - recall_m: 0.8773 - f1_m: 0.8940 - val_loss: 0.2781 - val_acc: 0.8926 - val_precision_m: 0.9066 - val_recall_m: 0.8803 - val_f1_m: 0.8933\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 30s 630us/step - loss: 0.2855 - acc: 0.8927 - precision_m: 0.9104 - recall_m: 0.8768 - f1_m: 0.8933 - val_loss: 0.2695 - val_acc: 0.8983 - val_precision_m: 0.9115 - val_recall_m: 0.8858 - val_f1_m: 0.8985\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 30s 621us/step - loss: 0.2802 - acc: 0.8949 - precision_m: 0.9120 - recall_m: 0.8798 - f1_m: 0.8956 - val_loss: 0.2686 - val_acc: 0.8955 - val_precision_m: 0.9093 - val_recall_m: 0.8835 - val_f1_m: 0.8962\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 28s 584us/step - loss: 0.2785 - acc: 0.8969 - precision_m: 0.9131 - recall_m: 0.8815 - f1_m: 0.8970 - val_loss: 0.2669 - val_acc: 0.8979 - val_precision_m: 0.9131 - val_recall_m: 0.8833 - val_f1_m: 0.8980\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 29s 604us/step - loss: 0.2782 - acc: 0.8964 - precision_m: 0.9132 - recall_m: 0.8804 - f1_m: 0.8965 - val_loss: 0.2593 - val_acc: 0.9021 - val_precision_m: 0.9158 - val_recall_m: 0.8913 - val_f1_m: 0.9034\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 30s 622us/step - loss: 0.2734 - acc: 0.8984 - precision_m: 0.9157 - recall_m: 0.8832 - f1_m: 0.8991 - val_loss: 0.2657 - val_acc: 0.8992 - val_precision_m: 0.9124 - val_recall_m: 0.8890 - val_f1_m: 0.9006\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 31s 654us/step - loss: 0.2678 - acc: 0.9006 - precision_m: 0.9173 - recall_m: 0.8848 - f1_m: 0.9007 - val_loss: 0.2602 - val_acc: 0.9034 - val_precision_m: 0.9144 - val_recall_m: 0.8942 - val_f1_m: 0.9042\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 30s 625us/step - loss: 0.2676 - acc: 0.8995 - precision_m: 0.9160 - recall_m: 0.8854 - f1_m: 0.9004 - val_loss: 0.2583 - val_acc: 0.9014 - val_precision_m: 0.9170 - val_recall_m: 0.8924 - val_f1_m: 0.9046\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 30s 619us/step - loss: 0.2606 - acc: 0.9028 - precision_m: 0.9190 - recall_m: 0.8881 - f1_m: 0.9033 - val_loss: 0.2514 - val_acc: 0.9041 - val_precision_m: 0.9169 - val_recall_m: 0.8937 - val_f1_m: 0.9051\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 30s 627us/step - loss: 0.2595 - acc: 0.9024 - precision_m: 0.9173 - recall_m: 0.8879 - f1_m: 0.9023 - val_loss: 0.2505 - val_acc: 0.9052 - val_precision_m: 0.9183 - val_recall_m: 0.8939 - val_f1_m: 0.9059\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 29s 609us/step - loss: 0.2539 - acc: 0.9038 - precision_m: 0.9190 - recall_m: 0.8904 - f1_m: 0.9044 - val_loss: 0.2468 - val_acc: 0.9073 - val_precision_m: 0.9185 - val_recall_m: 0.8968 - val_f1_m: 0.9075\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 30s 618us/step - loss: 0.2540 - acc: 0.9044 - precision_m: 0.9196 - recall_m: 0.8904 - f1_m: 0.9048 - val_loss: 0.2532 - val_acc: 0.9032 - val_precision_m: 0.9149 - val_recall_m: 0.8928 - val_f1_m: 0.9037\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 31s 645us/step - loss: 0.2498 - acc: 0.9065 - precision_m: 0.9208 - recall_m: 0.8930 - f1_m: 0.9067 - val_loss: 0.2499 - val_acc: 0.9029 - val_precision_m: 0.9163 - val_recall_m: 0.8926 - val_f1_m: 0.9043\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 30s 616us/step - loss: 0.2486 - acc: 0.9084 - precision_m: 0.9232 - recall_m: 0.8955 - f1_m: 0.9091 - val_loss: 0.2553 - val_acc: 0.9042 - val_precision_m: 0.9165 - val_recall_m: 0.8938 - val_f1_m: 0.9050\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 30s 628us/step - loss: 0.2420 - acc: 0.9097 - precision_m: 0.9239 - recall_m: 0.8967 - f1_m: 0.9101 - val_loss: 0.2471 - val_acc: 0.9062 - val_precision_m: 0.9177 - val_recall_m: 0.8983 - val_f1_m: 0.9079\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 30s 616us/step - loss: 0.2412 - acc: 0.9100 - precision_m: 0.9237 - recall_m: 0.8976 - f1_m: 0.9105 - val_loss: 0.2425 - val_acc: 0.9098 - val_precision_m: 0.9203 - val_recall_m: 0.9003 - val_f1_m: 0.9102\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 30s 620us/step - loss: 0.2382 - acc: 0.9109 - precision_m: 0.9249 - recall_m: 0.8987 - f1_m: 0.9116 - val_loss: 0.2495 - val_acc: 0.9064 - val_precision_m: 0.9179 - val_recall_m: 0.8987 - val_f1_m: 0.9082\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 30s 616us/step - loss: 0.2383 - acc: 0.9104 - precision_m: 0.9239 - recall_m: 0.8975 - f1_m: 0.9105 - val_loss: 0.2466 - val_acc: 0.9052 - val_precision_m: 0.9187 - val_recall_m: 0.8949 - val_f1_m: 0.9067\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 29s 608us/step - loss: 0.2349 - acc: 0.9122 - precision_m: 0.9258 - recall_m: 0.9007 - f1_m: 0.9131 - val_loss: 0.2408 - val_acc: 0.9083 - val_precision_m: 0.9216 - val_recall_m: 0.8987 - val_f1_m: 0.9100\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 31s 644us/step - loss: 0.2312 - acc: 0.9124 - precision_m: 0.9255 - recall_m: 0.9010 - f1_m: 0.9131 - val_loss: 0.2396 - val_acc: 0.9090 - val_precision_m: 0.9198 - val_recall_m: 0.9002 - val_f1_m: 0.9099\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 33s 686us/step - loss: 0.2305 - acc: 0.9145 - precision_m: 0.9275 - recall_m: 0.9020 - f1_m: 0.9146 - val_loss: 0.2425 - val_acc: 0.9100 - val_precision_m: 0.9191 - val_recall_m: 0.8999 - val_f1_m: 0.9094\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 32s 665us/step - loss: 0.2299 - acc: 0.9128 - precision_m: 0.9253 - recall_m: 0.9016 - f1_m: 0.9133 - val_loss: 0.2314 - val_acc: 0.9144 - val_precision_m: 0.9247 - val_recall_m: 0.9058 - val_f1_m: 0.9152\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 31s 646us/step - loss: 0.2292 - acc: 0.9134 - precision_m: 0.9261 - recall_m: 0.9010 - f1_m: 0.9134 - val_loss: 0.2355 - val_acc: 0.9127 - val_precision_m: 0.9225 - val_recall_m: 0.9041 - val_f1_m: 0.9132\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 31s 652us/step - loss: 0.2282 - acc: 0.9156 - precision_m: 0.9285 - recall_m: 0.9048 - f1_m: 0.9165 - val_loss: 0.2317 - val_acc: 0.9128 - val_precision_m: 0.9244 - val_recall_m: 0.9042 - val_f1_m: 0.9142\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 30s 625us/step - loss: 0.2212 - acc: 0.9169 - precision_m: 0.9298 - recall_m: 0.9054 - f1_m: 0.9174 - val_loss: 0.2420 - val_acc: 0.9093 - val_precision_m: 0.9220 - val_recall_m: 0.9007 - val_f1_m: 0.9112\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 30s 620us/step - loss: 0.2228 - acc: 0.9168 - precision_m: 0.9290 - recall_m: 0.9052 - f1_m: 0.9169 - val_loss: 0.2377 - val_acc: 0.9118 - val_precision_m: 0.9228 - val_recall_m: 0.9033 - val_f1_m: 0.9130\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 29s 612us/step - loss: 0.2167 - acc: 0.9171 - precision_m: 0.9288 - recall_m: 0.9070 - f1_m: 0.9178 - val_loss: 0.2376 - val_acc: 0.9130 - val_precision_m: 0.9213 - val_recall_m: 0.9058 - val_f1_m: 0.9135\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 29s 609us/step - loss: 0.2182 - acc: 0.9179 - precision_m: 0.9297 - recall_m: 0.9078 - f1_m: 0.9186 - val_loss: 0.2326 - val_acc: 0.9148 - val_precision_m: 0.9259 - val_recall_m: 0.9073 - val_f1_m: 0.9165\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 29s 606us/step - loss: 0.2168 - acc: 0.9186 - precision_m: 0.9299 - recall_m: 0.9088 - f1_m: 0.9193 - val_loss: 0.2315 - val_acc: 0.9151 - val_precision_m: 0.9241 - val_recall_m: 0.9075 - val_f1_m: 0.9157\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 30s 622us/step - loss: 0.2136 - acc: 0.9189 - precision_m: 0.9306 - recall_m: 0.9080 - f1_m: 0.9192 - val_loss: 0.2378 - val_acc: 0.9129 - val_precision_m: 0.9219 - val_recall_m: 0.9048 - val_f1_m: 0.9132\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 29s 608us/step - loss: 0.2112 - acc: 0.9206 - precision_m: 0.9312 - recall_m: 0.9111 - f1_m: 0.9211 - val_loss: 0.2302 - val_acc: 0.9149 - val_precision_m: 0.9228 - val_recall_m: 0.9078 - val_f1_m: 0.9152\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 28s 587us/step - loss: 0.2118 - acc: 0.9204 - precision_m: 0.9313 - recall_m: 0.9103 - f1_m: 0.9207 - val_loss: 0.2253 - val_acc: 0.9177 - val_precision_m: 0.9269 - val_recall_m: 0.9096 - val_f1_m: 0.9182\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 28s 583us/step - loss: 0.2096 - acc: 0.9198 - precision_m: 0.9306 - recall_m: 0.9102 - f1_m: 0.9203 - val_loss: 0.2331 - val_acc: 0.9126 - val_precision_m: 0.9229 - val_recall_m: 0.9045 - val_f1_m: 0.9136\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 28s 582us/step - loss: 0.2068 - acc: 0.9222 - precision_m: 0.9327 - recall_m: 0.9119 - f1_m: 0.9222 - val_loss: 0.2217 - val_acc: 0.9180 - val_precision_m: 0.9269 - val_recall_m: 0.9113 - val_f1_m: 0.9191\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 28s 582us/step - loss: 0.2031 - acc: 0.9226 - precision_m: 0.9329 - recall_m: 0.9131 - f1_m: 0.9229 - val_loss: 0.2287 - val_acc: 0.9173 - val_precision_m: 0.9260 - val_recall_m: 0.9109 - val_f1_m: 0.9184\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 28s 583us/step - loss: 0.2059 - acc: 0.9229 - precision_m: 0.9333 - recall_m: 0.9136 - f1_m: 0.9234 - val_loss: 0.2385 - val_acc: 0.9128 - val_precision_m: 0.9224 - val_recall_m: 0.9047 - val_f1_m: 0.9134\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.2045 - acc: 0.9211 - precision_m: 0.9324 - recall_m: 0.9125 - f1_m: 0.9224 - val_loss: 0.2273 - val_acc: 0.9155 - val_precision_m: 0.9248 - val_recall_m: 0.9086 - val_f1_m: 0.9166\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 28s 582us/step - loss: 0.1984 - acc: 0.9242 - precision_m: 0.9343 - recall_m: 0.9158 - f1_m: 0.9250 - val_loss: 0.2358 - val_acc: 0.9147 - val_precision_m: 0.9236 - val_recall_m: 0.9078 - val_f1_m: 0.9157\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 28s 587us/step - loss: 0.2021 - acc: 0.9244 - precision_m: 0.9345 - recall_m: 0.9140 - f1_m: 0.9241 - val_loss: 0.2264 - val_acc: 0.9179 - val_precision_m: 0.9267 - val_recall_m: 0.9113 - val_f1_m: 0.9189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 28s 583us/step - loss: 0.1975 - acc: 0.9249 - precision_m: 0.9354 - recall_m: 0.9155 - f1_m: 0.9254 - val_loss: 0.2249 - val_acc: 0.9186 - val_precision_m: 0.9274 - val_recall_m: 0.9115 - val_f1_m: 0.9194\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 28s 575us/step - loss: 0.1973 - acc: 0.9258 - precision_m: 0.9351 - recall_m: 0.9170 - f1_m: 0.9259 - val_loss: 0.2320 - val_acc: 0.9173 - val_precision_m: 0.9262 - val_recall_m: 0.9105 - val_f1_m: 0.9183\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1938 - acc: 0.9269 - precision_m: 0.9372 - recall_m: 0.9181 - f1_m: 0.9275 - val_loss: 0.2197 - val_acc: 0.9215 - val_precision_m: 0.9289 - val_recall_m: 0.9157 - val_f1_m: 0.9222\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1965 - acc: 0.9243 - precision_m: 0.9341 - recall_m: 0.9159 - f1_m: 0.9249 - val_loss: 0.2247 - val_acc: 0.9180 - val_precision_m: 0.9268 - val_recall_m: 0.9122 - val_f1_m: 0.9195\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 28s 579us/step - loss: 0.1953 - acc: 0.9266 - precision_m: 0.9357 - recall_m: 0.9180 - f1_m: 0.9268 - val_loss: 0.2146 - val_acc: 0.9206 - val_precision_m: 0.9289 - val_recall_m: 0.9150 - val_f1_m: 0.9219\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 28s 576us/step - loss: 0.1935 - acc: 0.9263 - precision_m: 0.9364 - recall_m: 0.9187 - f1_m: 0.9275 - val_loss: 0.2196 - val_acc: 0.9193 - val_precision_m: 0.9273 - val_recall_m: 0.9114 - val_f1_m: 0.9193\n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1874 - acc: 0.9286 - precision_m: 0.9380 - recall_m: 0.9198 - f1_m: 0.9288 - val_loss: 0.2178 - val_acc: 0.9192 - val_precision_m: 0.9271 - val_recall_m: 0.9133 - val_f1_m: 0.9201\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 28s 585us/step - loss: 0.1903 - acc: 0.9284 - precision_m: 0.9382 - recall_m: 0.9199 - f1_m: 0.9290 - val_loss: 0.2236 - val_acc: 0.9174 - val_precision_m: 0.9271 - val_recall_m: 0.9108 - val_f1_m: 0.9189\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 28s 574us/step - loss: 0.1917 - acc: 0.9273 - precision_m: 0.9363 - recall_m: 0.9191 - f1_m: 0.9276 - val_loss: 0.2250 - val_acc: 0.9196 - val_precision_m: 0.9288 - val_recall_m: 0.9134 - val_f1_m: 0.9211\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 28s 575us/step - loss: 0.1908 - acc: 0.9283 - precision_m: 0.9375 - recall_m: 0.9197 - f1_m: 0.9285 - val_loss: 0.2179 - val_acc: 0.9207 - val_precision_m: 0.9286 - val_recall_m: 0.9143 - val_f1_m: 0.9214\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1888 - acc: 0.9275 - precision_m: 0.9362 - recall_m: 0.9192 - f1_m: 0.9276 - val_loss: 0.2228 - val_acc: 0.9193 - val_precision_m: 0.9272 - val_recall_m: 0.9138 - val_f1_m: 0.9205\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1880 - acc: 0.9272 - precision_m: 0.9369 - recall_m: 0.9190 - f1_m: 0.9279 - val_loss: 0.2157 - val_acc: 0.9231 - val_precision_m: 0.9306 - val_recall_m: 0.9178 - val_f1_m: 0.9241\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1849 - acc: 0.9297 - precision_m: 0.9385 - recall_m: 0.9214 - f1_m: 0.9298 - val_loss: 0.2183 - val_acc: 0.9205 - val_precision_m: 0.9290 - val_recall_m: 0.9156 - val_f1_m: 0.9222\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1840 - acc: 0.9313 - precision_m: 0.9397 - recall_m: 0.9232 - f1_m: 0.9314 - val_loss: 0.2125 - val_acc: 0.9208 - val_precision_m: 0.9308 - val_recall_m: 0.9153 - val_f1_m: 0.9230\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1824 - acc: 0.9314 - precision_m: 0.9401 - recall_m: 0.9235 - f1_m: 0.9318 - val_loss: 0.2260 - val_acc: 0.9184 - val_precision_m: 0.9267 - val_recall_m: 0.9116 - val_f1_m: 0.9191\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1829 - acc: 0.9313 - precision_m: 0.9398 - recall_m: 0.9234 - f1_m: 0.9315 - val_loss: 0.2169 - val_acc: 0.9240 - val_precision_m: 0.9321 - val_recall_m: 0.9183 - val_f1_m: 0.9251\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1825 - acc: 0.9310 - precision_m: 0.9393 - recall_m: 0.9234 - f1_m: 0.9313 - val_loss: 0.2134 - val_acc: 0.9236 - val_precision_m: 0.9320 - val_recall_m: 0.9171 - val_f1_m: 0.9245\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 28s 576us/step - loss: 0.1799 - acc: 0.9311 - precision_m: 0.9397 - recall_m: 0.9234 - f1_m: 0.9315 - val_loss: 0.2175 - val_acc: 0.9221 - val_precision_m: 0.9295 - val_recall_m: 0.9169 - val_f1_m: 0.9232\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 28s 582us/step - loss: 0.1807 - acc: 0.9316 - precision_m: 0.9404 - recall_m: 0.9238 - f1_m: 0.9321 - val_loss: 0.2246 - val_acc: 0.9202 - val_precision_m: 0.9274 - val_recall_m: 0.9152 - val_f1_m: 0.9213\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1789 - acc: 0.9316 - precision_m: 0.9390 - recall_m: 0.9247 - f1_m: 0.9318 - val_loss: 0.2169 - val_acc: 0.9226 - val_precision_m: 0.9313 - val_recall_m: 0.9161 - val_f1_m: 0.9236\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 28s 587us/step - loss: 0.1812 - acc: 0.9312 - precision_m: 0.9387 - recall_m: 0.9230 - f1_m: 0.9308 - val_loss: 0.2156 - val_acc: 0.9231 - val_precision_m: 0.9307 - val_recall_m: 0.9182 - val_f1_m: 0.9244\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1735 - acc: 0.9338 - precision_m: 0.9418 - recall_m: 0.9268 - f1_m: 0.9342 - val_loss: 0.2142 - val_acc: 0.9235 - val_precision_m: 0.9313 - val_recall_m: 0.9177 - val_f1_m: 0.9244\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 28s 581us/step - loss: 0.1781 - acc: 0.9319 - precision_m: 0.9397 - recall_m: 0.9245 - f1_m: 0.9320 - val_loss: 0.2185 - val_acc: 0.9234 - val_precision_m: 0.9317 - val_recall_m: 0.9178 - val_f1_m: 0.9247\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1756 - acc: 0.9331 - precision_m: 0.9413 - recall_m: 0.9260 - f1_m: 0.9336 - val_loss: 0.2195 - val_acc: 0.9195 - val_precision_m: 0.9280 - val_recall_m: 0.9145 - val_f1_m: 0.9212\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 28s 581us/step - loss: 0.1781 - acc: 0.9321 - precision_m: 0.9403 - recall_m: 0.9259 - f1_m: 0.9330 - val_loss: 0.2256 - val_acc: 0.9193 - val_precision_m: 0.9267 - val_recall_m: 0.9132 - val_f1_m: 0.9199\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1734 - acc: 0.9335 - precision_m: 0.9413 - recall_m: 0.9260 - f1_m: 0.9336 - val_loss: 0.2243 - val_acc: 0.9194 - val_precision_m: 0.9260 - val_recall_m: 0.9143 - val_f1_m: 0.9201\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 28s 580us/step - loss: 0.1732 - acc: 0.9349 - precision_m: 0.9429 - recall_m: 0.9280 - f1_m: 0.9354 - val_loss: 0.2210 - val_acc: 0.9215 - val_precision_m: 0.9295 - val_recall_m: 0.9165 - val_f1_m: 0.9230\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1736 - acc: 0.9358 - precision_m: 0.9428 - recall_m: 0.9283 - f1_m: 0.9355 - val_loss: 0.2163 - val_acc: 0.9224 - val_precision_m: 0.9309 - val_recall_m: 0.9170 - val_f1_m: 0.9239\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1710 - acc: 0.9344 - precision_m: 0.9418 - recall_m: 0.9274 - f1_m: 0.9345 - val_loss: 0.2143 - val_acc: 0.9232 - val_precision_m: 0.9307 - val_recall_m: 0.9188 - val_f1_m: 0.9247\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1708 - acc: 0.9361 - precision_m: 0.9435 - recall_m: 0.9290 - f1_m: 0.9362 - val_loss: 0.2127 - val_acc: 0.9252 - val_precision_m: 0.9323 - val_recall_m: 0.9198 - val_f1_m: 0.9260\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1699 - acc: 0.9345 - precision_m: 0.9421 - recall_m: 0.9278 - f1_m: 0.9349 - val_loss: 0.2151 - val_acc: 0.9233 - val_precision_m: 0.9312 - val_recall_m: 0.9175 - val_f1_m: 0.9243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 28s 576us/step - loss: 0.1700 - acc: 0.9358 - precision_m: 0.9426 - recall_m: 0.9285 - f1_m: 0.9355 - val_loss: 0.2122 - val_acc: 0.9238 - val_precision_m: 0.9313 - val_recall_m: 0.9183 - val_f1_m: 0.9248\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 28s 579us/step - loss: 0.1668 - acc: 0.9364 - precision_m: 0.9437 - recall_m: 0.9296 - f1_m: 0.9366 - val_loss: 0.2124 - val_acc: 0.9258 - val_precision_m: 0.9320 - val_recall_m: 0.9208 - val_f1_m: 0.9264\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 28s 579us/step - loss: 0.1697 - acc: 0.9345 - precision_m: 0.9419 - recall_m: 0.9278 - f1_m: 0.9348 - val_loss: 0.2198 - val_acc: 0.9226 - val_precision_m: 0.9294 - val_recall_m: 0.9175 - val_f1_m: 0.9234\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 28s 579us/step - loss: 0.1698 - acc: 0.9348 - precision_m: 0.9424 - recall_m: 0.9285 - f1_m: 0.9354 - val_loss: 0.2150 - val_acc: 0.9244 - val_precision_m: 0.9315 - val_recall_m: 0.9198 - val_f1_m: 0.9257\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 28s 576us/step - loss: 0.1693 - acc: 0.9348 - precision_m: 0.9429 - recall_m: 0.9285 - f1_m: 0.9356 - val_loss: 0.2170 - val_acc: 0.9226 - val_precision_m: 0.9289 - val_recall_m: 0.9187 - val_f1_m: 0.9237\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 28s 577us/step - loss: 0.1673 - acc: 0.9358 - precision_m: 0.9427 - recall_m: 0.9289 - f1_m: 0.9358 - val_loss: 0.2289 - val_acc: 0.9217 - val_precision_m: 0.9276 - val_recall_m: 0.9178 - val_f1_m: 0.9227\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 27s 572us/step - loss: 0.1705 - acc: 0.9340 - precision_m: 0.9421 - recall_m: 0.9280 - f1_m: 0.9350 - val_loss: 0.2205 - val_acc: 0.9215 - val_precision_m: 0.9285 - val_recall_m: 0.9172 - val_f1_m: 0.9228\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 28s 579us/step - loss: 0.1638 - acc: 0.9365 - precision_m: 0.9443 - recall_m: 0.9302 - f1_m: 0.9372 - val_loss: 0.2101 - val_acc: 0.9262 - val_precision_m: 0.9326 - val_recall_m: 0.9207 - val_f1_m: 0.9266\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 27s 571us/step - loss: 0.1649 - acc: 0.9370 - precision_m: 0.9442 - recall_m: 0.9306 - f1_m: 0.9373 - val_loss: 0.2130 - val_acc: 0.9248 - val_precision_m: 0.9319 - val_recall_m: 0.9206 - val_f1_m: 0.9262\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 28s 576us/step - loss: 0.1599 - acc: 0.9382 - precision_m: 0.9455 - recall_m: 0.9318 - f1_m: 0.9386 - val_loss: 0.2195 - val_acc: 0.9234 - val_precision_m: 0.9304 - val_recall_m: 0.9193 - val_f1_m: 0.9248\n"
     ]
    }
   ],
   "source": [
    "# Traing the experiment.\n",
    "# Epoch and metrics(accuracy, f1, precision, recall) logs are dumping over TensorBoard and MLFlow servers.\n",
    "# For tensorboard, http://localhost:6006/\n",
    "# For MLFlow server, http://localhost:5000/\n",
    "experiment.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.20106277614831924,\n",
       " 'accuracy': 0.9314000070095062,\n",
       " <function fmnist.utils.Metrics.precision_m(y_true, y_pred)>: 0.9367335855960846,\n",
       " <function fmnist.utils.Metrics.recall_m(y_true, y_pred)>: 0.9269999980926513,\n",
       " <function fmnist.utils.Metrics.f1_m(y_true, y_pred)>: 0.9318393468856812}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores = experiment.evaluate()\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='http://localhost:6006/', width=800, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:5000/#/experiments/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe70a69bb70>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from mlflow.tracking import MlflowClient\n",
    "from IPython.display import IFrame\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(os.getenv('MLFLOW_EXPERIMENT_NAME'))\n",
    "experiment.experiment_id\n",
    "\n",
    "IFrame(src='http://localhost:5000/#/experiments/{}'.format(experiment.experiment_id), width=800, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment in Docker..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.mlflow.org/docs/latest/cli.html#mlflow-models-build-docker\n",
    "\n",
    "# !mlflow models build-docker '/mlflow/1/cfc82224b9e843b39504bbd50dbe059e/artifacts/model/' -m model_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.keras.load_model('/mlflow/1/cfc82224b9e843b39504bbd50dbe059e/artifacts/model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
